# 黑马点评面试问题总结

##  优惠劵秒杀

### 1、聊聊你的乐观锁。数据库层面的update？update也要加锁的，那这样你的并发量很低，有想过解决方式吗？

（被三个面试官指责我这种实现不好，有个面试官建议我用redis扣减库存）

* 缺点：高并发时，数据库需要处理大量冲突，**性能可能下降**。秒杀请求大部分失败，**用户体验较差。**
* 优化方式：1、乐观锁从判断和之前的查询的库存一样到判断库存大于0，提高并发量。2、用户请求秒杀时，先检查 Redis 中的库存，如果库存不足直接返回失败。后续开辟一个线程通过消息队列异步将成功的请求持久化到数据库。
* 注意：在redis中会保存库存数量以及键为优惠劵id的set，set里保存userid。会判断库存是否大于0以及用户是否下过单了（也就是set里是否有userid）。



悲观锁和乐观锁的区别：

悲观锁：锁包含了判断逻辑和更新逻辑。

乐观锁：判断逻辑没有加锁，只是在提交更新数据时再次判断数据是否为之前读取的数据。



### 2、你订单接口的幂等性是怎么做的？（意思就是post请求带着：一个用户id，一个优惠卷id。发送多次请求，如何保证只有一个成功）也就是一人一单问题。

1. 在redis中判断是否下过单了（redis会过期，所以不仅redis会判断，数据库也会保存订单）。

2. 在加锁逻辑时会保证同一个用户不能在同一时刻下单，也就是另一个线程也是同一个userid就不能加锁了。
   * 可重入的概念与之不相同，那是在加锁的过程中同一个线程又有加同一个锁的逻辑，可重复加锁。
   * 如果另一个线程带有不同userid就能加锁，于是两个线程同时对数据库进行操作，但由于乐观锁，只会有一个线程进行stock扣减。
   * 乐观锁先读取stock是否大于0，然后stcok减一，然后用新stock提交到数据库更新，但是在提交前还会判断stock是否大于0，如不大于0，则失败。**失败后直接返回库存不够，不用重试。**
3. 在创建订单逻辑时也会判断数据库中有userid和vocherid的数据订单是否已存在。

一锁二判三更新。

* 注意锁的粒度得是锁住用户id。
* 锁的释放必须在事务提交后。事务还未提交时，但锁已经释放,**数据库中的数据仍是原来的状态**,另一个线程获得锁，进入逻辑，读取到了**旧的库存(由于MVCC机制,只会读取以前的快照,除非事务提交)**.
* 得用代理对象调用方法保证事务的生效
* 解决集群情况下锁失效问题：使用分布式锁，而不是synchronized锁。



### 3、分布式锁问题

分布式锁防止误删锁：每个线程在删除自己的锁时判断锁是不是自己的，也就是判断redis中锁有没有自己的线程标识。而且还要保证**判断锁是不是自己并且删锁**是原子操作。

Redission可重入锁的过程：判断锁是否存在，若存在判断锁是不是自己的，若是则锁计数加一，设置过期时间。

tryLock和Lock方法的区别：

* 前者未获取锁直接返回，但是又可能会出现大量线程轮询，使redis服务的压力增大
* 后者未获取锁直接堵塞，减少了很多无效请求，但是长时间堵塞，线程利用率低。
* tryLock() 更适用于快速尝试获取锁的场景，比如资源敏感、用户操作需要立即响应的业务。lock(long leaseTime, TimeUnit unit) 更适合在高并发情况下，需要确保锁可用且减少 Redis 压力的场景。在高并发场景下，优先推荐使用 lock(long leaseTime, TimeUnit unit)，因为它能提供**更稳定的性能表现，同时降低 Redis 的负载**。



## 登录

### 1、使用redis存储session和使用jwt的区别

* 前者的优点：集中式存储，支持服务端控制；存储敏感信息；通过ttl机制可以灵活控制会话生命周期。
* 后者的话服务端无法单独使其失效；存储在客户端，又可能泄露；jwt包含很多信息，token增大，造成带宽浪费。
* 分布式架构多个服务可以通过redis同步会话状态。

## 关注和点赞：

### 1、我关注的人和关注我的人怎么设计的？

判断关注：数据库中保存userid以及userid关注的人的foller_user_id这种数据，判断是否关注某个id时，去数据库查询判断。

关注和取消关注操作：前端发送请求时携带是否关注的信息，若是为true，则后端在数据库中保存记录，同时在redis中使用set数据结构保存每个用户所关注的用户是谁。若是为false，从数据库中删除信息，成功后则把redis信息也删除。

查看共同关注：使用redis中的set的交集，快速得出共同关注的userid，然后根据id从数据库中找出用户信息并返回到前端。

### 2、那种大v，粉丝数量应该很多，这种热key+大key你是怎么处理的？

### 如何处理bigkey:

* 分割bigkey：二次哈希拆分为多个Hash
* 手动清理：使用SCAN命令分批次删除；开启 lazy-free（惰性删除/延迟释放）采用异步方式延迟释放 key 。
* **采用合适的数据结构**：例如，**大文件二进制数据不使用 String 保存**（对于特别大的文件，可以将文件切分成多个块，分别存储在 Redis 的 **HASH 或 LIST** 数据结构中。）、使用 HyperLogLog 统计页面 UV、Bitmap 保存状态信息（0/1）如用户是否签到或者缓存是否存在数据库。

### 处理hotkey：

处理 hotkey 会占用大量的 CPU 和带宽，可能会影响 Redis 实例对其他请求的正常处理。

解决办法：

* 读写分离
* Redis Cluster：热点数据分散在多个redis实例中
* 二级缓存/本地缓存

### Redis宕机怎么办：

* Redis高可用配置：Redis集群，主从复制，结合Sentinel实现主从切换。
* 数据持久化：RDB和AOF
* 缓存降级：宕机时，系统可以临时回退到数据库或其他后备存储（如 MySQL）。代码实现双写策略：登录信息同时写入Redis和数据库。Redis无法访问时从数据库加载用户信息。未避免数据库压力过大，非核心功能暂时不可用。
* 本地缓存。**例如 Caffeine 或 Guava Cache**。


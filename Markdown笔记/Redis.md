# Redis

## 1、消息队列

如今的互联网应用大都是采用 分布式系统架构 设计的，所以 消息队列 已经逐渐成为企业应用系统 内部通信 的核心手段，它具有 **低耦合、可靠投递、可重试、广播、流量控制、最终一致性** 等一系列功能。

### List作为消息队列（Redis 1.0就引入的list结构）

Redis有brpop接口，该接口有一个参数是超时时间，如果list为空，那么Redis服务端不会立刻返回结果，它会等待list中有新数据后在返回或是等待最多一个超时时间后返回空。实现了长轮询，该效果等同于服务端推送，消费者能立刻感知到新的消息，而且通过设置合理的超时时间，使系统资源的消耗降到很低。

消息支持持久化，但是消息依然会丢失。如果应用在处理消息前异常宕机了，**消息就丢失**了，如果使用lindex这样的只读命令先读取消息处理完毕后在删除，又需要额外的机制来保证一条消息不会被其他消费者重复读到。好在list有rpoplpush或brpoplpush这样的接口，可以原子性的从一个list中移除一个消息并加入另一个list。这种方式为消息的消费增加了ack机制。

#### 缺点

1、**只支持单消费者**.有一个很致命的问题，它没有广播功能，一个消息只能被消费一次。可能你会说那弄多个list，生产者向每个list中都投递消息，每个消费者处理自己的list不就行了吗。这样第一是性能不会太好，因为同一个消息需要被重复的投递，第二是这样的设计违反了生产者和消费者解耦的原则。

2、消息不保存在服务端，有丢失风险.

###   Redis 2.0 pubsub

pubsub引入一个概念叫channel，生产者通过publish接口投递消息时会指定channel，消费者通过subscribe接口订阅它关心的channel，调用subscribe后这条连接会进入一个特殊的状态，通常不能在发送其他请求。消费者可以会订阅一批channel，这里psubscribe传入一个通配符表达的channel，Redis服务端按照规则推送所有匹配channel的消息给对应的客户端。

pubsub既能单播又能广播，还支持channel的简单正则匹配。

#### 缺点

1、消息不能持久化，实时性优先，**没有ack机制，消息不保存在服务端**。pubsub的**消息数据是瞬时的**，它在Redis服务端不做保存，publish发送到Redis的消息会立刻推送到所有当时subscribe连接的客户端，如果当时客户端因为网络问题断连，那么就会错过这条消息，当客户端重连后，它没法重新获取之前那条消息，甚至无法判断是否有消息丢失。

2、**消息堆积有上限**，不管消费者处理能力如何，如果消费者应用处理能力不足，消息就会在Redis的client buf中堆积，当堆积数据超过一个阈值后会断开这条连接，这意味着这些消息全部丢失了，在也找不回来了。

###  Redis 5.0 stream

消费组隔离，具有广播机制。

消费者采用拉取方式，设置timeout在没有消息时堵塞，长轮询机制，消费速率是和消费者自身吞吐相匹配。

消息不会丢失：1、重启恢复数据，保存在aof和rdb中 。2、消费组存储读取的位点，连接断开后重连能从原来位点继续。

3、Ack机制，标识没有ack的消息，保证消息至少被处理一次。可以重新读取或者组内其他消费者也能读取这条消息，只需归属自己下面继续处理。

**时间回拨问题**：为了保证消息是有序的，因此Redis生成的ID是单调递增有序的。由于ID中包含时间戳部分，为了避免服务器时间错误而带来的问题（例如服务器时间延后了），Redis的每个Stream类型数据都维护一个latest_generated_id属性，用于记录最后一个消息的ID。**若发现当前时间戳退后（小于latest_generated_id所记录的），则采用时间戳不变而序号递增的方案来作为新消息ID**（这也是序号为什么使用int64的原因，保证有足够多的的序号），从而保证ID的单调递增性质。

**消息转移**： XCLAIM mq mqGroup consumerB 3600000 1553585533795-1

转移除了要指定ID外，还需要指定IDLE，保证是长时间未处理的才被转移。被转移的消息的IDLE会被重置，用以保证不会被重复转移，以为可能会出现将过期的消息同时转移给多个消费者的并发操作，设置了IDLE，则可以避免后面的转移不会成功，因为IDLE不满足条件。例如连续两条转移操作，第二条不会成功。

#### 缺点

1、消息队列很重要的一个功能就是削峰填谷，就意味着steam中需要堆积更多的消息，而Redis作为一个全内存的产品，**数据堆积的成本**比磁盘高。

2、故障情况无法保证了消息至少被消费一次，因为消息会丢失。线上生产环境的Redis都是高可用架构，当主节点宕机后通常不会走恢复逻辑，而是直接切换到备节点继续提供服务，而Redis的同步方式是异步同步，这意味着主节点上新写入的数据可能还没同步到备节点，在切换后这部分数据就丢失了。所以在故障恢复中Redis中的数据可能会丢失一部分，在这样的背景下无论stream的接口设计的多么完善，都不能保证消息至少被消费一次。【宕机会丢失数据，因为开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到 AOF 缓冲区 `server.aof_buf` 中，然后再写入到 AOF 文件中（此时还在系统内核缓存区未同步到磁盘），最后再根据持久化方式（ `fsync`策略）的配置来决定何时将系统内核缓存区的数据同步到硬盘中的】

3.每条消息仅被处理一次还需要应用逻辑的介入。消息被重复处理要么是生产者重复投递，要么是消费者重复消费。

前者Redis stream为每个消息都设置了一个唯一递增的id，存在就说明已经投递成功，不存在则重新投递。

后者是消费者读取的消息处理完还未ack，即发生异常，恢复后会导致重复消费，但通过业务改造，使ack和消费消息做到事务性。



###  延时任务

延时任务有哪些：

- 订单超时自动取消。
- 用户活动过期自动清理。
- 定时任务调度。

1. redis过期事件监听（pub/sub 模式）

   监听__keyevent@<db>__:expired  channel，可以拿到过期的 key 的消息，进而实现了延时任务功能。

**时效性差。**过期事件消息是在 Redis 服务器删除 key 时pub（发布）的，而不是一个 key 过期之后就会就会直接发布。

​            redis删除策略：**惰性删除**：只会在取出 key 的时候才对数据进行过期检查。**定期删除**：每隔一段时间抽取一批 key 执行删除过期 key 操作。

**丢消息，没有持久化功能**。redis 的 pub/sub 模式中的消息并不支持持久化，这与消息队列不同。当没有订阅者时，消息会被直接丢弃，在 Redis 中不会存储该消息。

**需要解决重复消费问题**，增加代码开发量。Redis 的 pub/sub 模式目前只有广播模式，这意味着当生产者向特定频道发布一条消息时，所有订阅相关频道的消费者都能够收到该消息。

2. 延迟队列

   Redisson 的延迟队列 **RDelayedQueue** 是基于 Redis 的 **SortedSet** 来实现的。扫描 SortedSet 中过期的元素，然后将这些过期元素从 SortedSet 中移除，并将它们加入到就绪消息列表中。就绪消息列表是一个阻塞队列，有消息进入就会被监听到。这样做可以避免对整个 SortedSet 进行轮询，提高了执行效率。

   **减少丢消息的可能**，数据持久化，只可能丢失一点消息。

   **不存在重复消费问题。**每个客户端都是从同一个目标队列中获取任务的，不存在重复消费的问题。

##  2、redis持久化

### RDB持久化（Redis Database Backup）

Redis创建快照来获得存储在内存里面的数据在 **某个时间点** 上的副本。

快照持久化是 Redis **默认**采用的持久化方式。

- `save` : 同步保存操作，会阻塞 Redis 主线程；
- `bgsave` : fork 出一个子进程，子进程执行，不会阻塞 Redis 主线程，默认选项。

### AOF持久化（append-only file）

每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到 AOF 缓冲区，然后再写入到AOF 文件中（此时还在系统内核缓冲区），AOF 缓冲区根据对应的持久化方式（ `fsync` 策略）向硬盘做同步操作。

**AOF为什么在执行完命令之后记录日志？**  

**关系型数据库（如 MySQL的Redo log）：**

**数据一致化优先**：通常都是执行命令之前记录日志（方便故障恢复），这保证了强一致性，防止丢失事务。事务失败了也可以回滚。这样可以在任何意外情况（如系统崩溃）发生时进行 **完整的故障恢复**。同时在恢复时，MySQL 会读取日志文件，并根据事务的执行情况进行重做或回滚。

**AOF**：

从**性能优先**角度考虑，在命令执行完之后再记录，不会阻塞当前的命令执行；Redis是缓存，日志仅用于异常恢复，容忍一定程度的数据丢失。

缺点：Redis 的 AOF 则是**操作后才记录日志**，如果发生崩溃，**更改可能丢失**。这就导致 Redis 的一致性（特别是在持久化方面）要稍弱一些，更适合需要性能优先的场景。且在执行完命令之后记录日志会**阻塞后续其他命令**的执行。

#### AOF重写

Redis 将 AOF 重写程序放到子进程里执行。维护一个 **AOF 重写缓冲区**，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。

#### 混合持久化（**AOF 重写的改进**）

* 减少重写时间和提高数据恢复速度。

混合持久化并不是同时开启aof和rdb的持久化，而是两者结合的一种模式。

混合持久化模式在 AOF 文件开头写入 RDB 快照内容，相当于将一个数据压缩的快照直接写入 AOF 文件。这样，Redis 恢复时可以通过一次加载这个 RDB 内容来迅速还原大量数据，速度远快于仅使用 AOF 的逐条重放。通过这种方式，Redis 能提供**较快的重启时间（**如纯 RDB）和**更小的数据丢失风险**（如纯 AOF）。

###  RDB和AOF比较

RDB优于AOF：

* RDB 文件**空间占用小，**存储的内容是经过压缩的二进制数据，适合备份容灾。AOF 文件通常会比 RDB 文件大很多。重写占内存，重写期间到达的所有写入命令都会写入磁盘两次。
* 使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，**速度非常快。**

AOF优于RDB：

* AOF**数据安全**比RDB好，AOF 支持秒级数据丢失。
* AOF 以一种**易于理解和解析**的格式包含所有操作的日志。



## 3、redis过期时间设置

Redis 中除了字符串类型有自己独有设置过期时间的命令 `setex` 外，其他方法都需要依靠 `expire` 命令来设置过期时间。

过期时间除了有助于缓解内存的消耗，还有什么作用？比如，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在 1 分钟内有效，用户登录的 Token 可能只在 1 天内有效。

#### 如何处理hotkey

处理 hotkey 会占用大量的 CPU 和带宽，可能会影响 Redis 实例对其他请求的正常处理。此外，如果突然访问 hotkey 的请求超出了 Redis 的处理能力，Redis 就会直接宕机。这种情况下，大量请求将落到后面的数据库上，可能会导致数据库崩溃。

1. 读写分离：主节点写，从节点读
2. 使用redis cluster：热点数据分散存储
3. 二级缓存，将hotkey存放一份到jvm本地内存中

#### reids bigkey

原因：程序设计不当；对于业务的数据规模考虑不周到；未及时清理垃圾数据

bigkey 除了会消耗更多的内存空间和带宽，还会对性能造成比较大的影响：客户端超时阻塞（客户端很久没有收到响应）、网络阻塞、工作线程阻塞。

处理bigkey：

1. 分割bigkey。含有上万字段数量的 Hash 按照一定策略（比如二次哈希）拆分为多个 Hash。
2. 手动清理。
3. 采用合适的数据结构：例如，文件二进制数据不使用 String 保存（使用List 类型、Stream 类型或者将大文件二进制数据分片存储在 Hash 中）、使用 HyperLogLog 统计页面 UV、Bitmap 保存状态信息（0/1）。
4. 开启 lazy-free（惰性删除/延迟释放），异步延迟释放。

##  4、redis生产问题

### 缓存穿透

原因：缓存中以及数据库中都不存在key

解决办法：

1. 参数校验，不合法数据（比如查询的数据库 id 不能小于 0、传入的邮箱格式不对）直接返回
2. 缓存无效key(缓存空对象)，并设置过期时间，但不能从根本上解决问题。因为如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。但也可以设置过期时间短一些。
3. 布隆过滤器，返回的结果是概率性的，而不是非常准确的，并且，存放在布隆过滤器的数据不容易删除。**布隆过滤器**能解决缓存穿透、**海量数据去重**。占用空间更少并且效率更高，缺点是其返回的**结果是概率性的且不易删除**。由于哈希冲突，布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。
   * 减少布隆过滤器误判（发生了哈希碰撞）：**合理设置位数组大小（m）和哈希函数数量（k）**。
4. 接口限流，根据用户或者 IP 对接口进行限流，对于异常频繁的访问行为，还可以采取黑名单机制，例如将异常 IP 列入黑名单。

### 缓存击穿

原因：缓存击穿中，请求的 key 对应的是 **热点数据** ，请求瞬时打到了数据库中，该数据 存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期） 。

解决方法：

1. 永不过期（不推荐）,使用逻辑过期方法.
2. **热点数据**提前预热（推荐）针对热点数据提前预热，将其存入缓存中并设置**合理的过期时间**比如秒杀场景下的数据在秒杀结束之前不过期。逻辑过期方法中线程发现过期后去数据库读取数据前**也是要加锁的**。**而且未获取到锁会返回脏数据。**
3. **加互斥锁**（看情况）：在缓存失效后，通过设置互斥锁确保只有一个请求去查询数据库并更新缓存。

### 缓存雪崩

缓存雪崩导致的原因是缓存中的大量或者所有数据失效，比如大量数据同一时间过期或者服务器宕机

解决方法：

针对redis不可用：

1. redis集群，缓存数据库分布式部署
2. 多级缓存，本地缓存和redis缓存
3. 缓存业务降级限流策略

针对缓存同时失效：

1. 设置随机失效时间（可选）
2. 提前预热：定时任务刷新缓存，定时触发；提前加载热点数据，使用消息队列，将数据库中的热点数据的主键或者 ID 发送到消息队列中，然后由缓存服务消费消息队列中的数据，根据主键或者 ID 查询数据库并更新缓存。
3. 持久缓存（看情况）

### 主从复制

1. 数据冗余，是持久化之外的一种数据冗余方式。
2. 故障恢复
3. 负载均衡
4. 高可用基石

##  5、redis缓存

引入缓存提高性能

全量缓存，写在数据库，定时用数据库数据刷新缓存。缺点：数据不一致，不常访问的数据留在了缓存中

改进：缓存设置过期时间，写缓存写在数据库，读先读缓存，不在缓存则读数据库，再更新缓存。如此缓存只保留热数据。

继续改进：为了解决数据不一致，**数据库和缓存都更新**。对应的方案：1、先更新缓存，后更新数据库；2、先更新数据库，后更新缓存。不考虑并发，会出现第一次成功，第二次失败的情况。

同时在**「并发」**场景下无法保证缓存和数据一致性。并且更新数据库 + 更新缓存缓存利用率不高，每次数据发生变更，都「无脑」更新缓存，但是缓存中的数据不一定会被「马上读取」，这就会导致缓存中可能存放了很多不常访问的数据，浪费缓存资源。

更新数据库 + 更新缓存不可行。

考虑删除缓存保证一致性。

**先删除缓存，后更新数据库**：a删除缓存，去更新数据库，过程中，b缓存没读取到，去数据库读过旧的值后更新缓存为旧的值，缓存旧值，数据库新值，不一致。

解决办法：**延迟双删**。在线程 A 删除缓存、更新完数据库之后，先「休眠一会」，再「删除」一次缓存。这样一来，下次就可以从数据库读取到最新值，写入缓存。

缓存的操作放在第二步的原因：**缓存的写入速度是比数据库的写入速度快很多。**

**先更新数据库，后删除缓存**：会出现不一致，但概率很低，必须得是缓存本来已经失效，a去数据库读取，b又去更新数据库，且删除缓存（此时没有缓存），之后a才会将读取的旧值覆盖到缓存中，b时间明显更长，所以采用这种方案。

考虑第二步失败导致的问题。

1. 异步重试，不能同步重试。

   引入消息队列保证第二步操作缓存能够重试。但是重试的请求也会丢失（项目重启）。

   消息队列的好处：1、**保证可靠性**：写到队列中的消息，成功消费之前不会丢失（重启项目也不担心）  2、**保证消息成功投递**：下游从队列拉取消息，成功消费后才会删除消息，否则还会继续投递消息给消费者（符合我们重试的场景）

  消息队列的不利因素考量：写队列失败和消息队列的维护成本问题：

  **写队列失败**：操作缓存和写消息队列，「同时失败」的概率其实是很小的

  **维护成本**：我们项目中一般都会用到消息队列，维护成本并没有新增很多

2. **订阅数据库变更日志，再操作缓存**。

   业务应用在修改数据时，「只需」修改数据库，无需操作缓存。当一条数据发生修改时，MySQL 就会产生一条变更日志（Binlog），我们可以订阅这个日志，拿到具体操作的数据，然后再根据这条数据，去删除对应的缓存。

   成熟的开源中间件，例如阿里的 **canal**。canal 主要用于捕获 MySQL 数据库的 Binlog 日志，自动把数据库变更日志「投递」给下游的消息队列。**无需考虑写消息队列失败情况**：只要写 MySQL 成功，Binlog 肯定会有。

   

**在「先更新数据库，再删除缓存」方案下，「读写分离 + 主从库延迟」其实也会导致不一致**

a更新主库并删除缓存后，b从从库读取，此时从库还未达到与主库一致，所以是旧值，用旧值覆盖缓存，然后从库被更新为新值了。

两种延迟双删，分别对应两种方案：

解决办法：**延迟双删**。在「先更新数据库，再删除缓存」方案下，线程 A 可以生成一条「延时消息」，写到消息队列中，消费者延时「删除」缓存。为了把缓存清掉，这样一来，下次就可以从数据库读取到最新值，写入缓存。但这也只是尽可能保证一致性而已，需要**控制主从库延迟。**

### 缓存读写策略（主动更新缓存方案）

1. 旁路缓存模式(Cache Aside Pattern)

   首次请求数据不一定在缓存中，解决方法：热点数据提前放入。

   若写频繁则缓存频繁删除，命中率降低。解决方法：删除缓存变为更新缓存，但是要保证一致性。加锁保证强一致性；给缓存加一个较短的过期时间保证不一致影响较小。

   

2. 读写穿透模式(write/read through pattern)：很少使用，redis没有用过

   写的时候：cache不存在，则去更新数据库。cache存在更新缓存，由缓存自己更新数据库。

   读的时候：cache不存在，从db加载数据到cache然后再返回数据。

3. 异步缓存写入(write behind pattern)

   更新的时候只更新缓存，由缓存异步更新数据库。

   消息队列中消息的异步写入磁盘、MySQL 的 Innodb Buffer Pool 机制都用到了这种策略。

   非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。

   MySQL 的 Innodb Buffer Pool 机制：数据的修改并不会立即写回磁盘，而是先修改 Buffer Pool 中的数据页（即“脏页”），然后批量刷新到磁盘。这样可以减少磁盘 IO 并提高写入性能。

##  6、Redis堵塞原因

1. AOF
   * 日志记录堵塞
   * 刷盘堵塞：当磁盘压力太大的时候，会导致 `fsync` 操作发生阻塞，主线程调用 `write` 函数时也会被阻塞。`fsync` 完成后，主线程执行 `write` 才能成功返回。
   * 重写AOF堵塞：将缓冲区中新数据写到新文件的过程中会产生阻塞.

2. save命令创建RDB堵塞，而不是bgsave命令。

3. 时间复杂度可能在 O(N) 以及以上的命令会发生堵塞。比如：返回指定 Sorted Set 中指定排名范围内的所有元素；移除 Sorted Set 中指定排名范围/指定 score 范围内的所有元素；KEYS *。

4. 清空数据库。

5. 大 key 。

   大key引发：网络堵塞，客户端超时，阻塞工作线程（删除时）。

   * 删除大key。释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，会堵塞当前释放内存的应用程序。**可以采用分批次删除和异步删除的方式进行。**
   * 查找大key。使用 SCAN 命令来查找大 key；分析 RDB 文件来找出 big key。

## 7、Redis底层数据结构

### 1、SDS 简单动态字符串

头部+数据+\0。SDS 除了保存redis中的字符串值以外，SDS 还可以作为**缓冲区**（buffer）：包括 AOF 模块中的AOF缓冲区以及客户端状态中的输入缓冲区。

头部：

* len，表示SDS保存字符串的长度。

* alloc，除过头部与末尾的\0, 剩余的字节数.

优点（为啥使用SDS表示字符串）：

* O(1)复杂度获取字符串长度

* 杜绝缓冲区溢出：字符串修改时会先根据len判断空间是否足够

* 减少修改字符串时内存空间重新分配次数。由于`len`属性和`alloc`属性的存在，对于修改字符串SDS实现了**空间预分配**和**惰性空间释放**（字符串缩短后多余的字节数量会被记录在 SDS 的 `alloc` 属性中，这些多余的内存空间不会浪费，而是保留下来以备后续字符串增长操作直接使用，无需重新分配内存）两种策略。

* 二进制安全，可以保存二进制数据：对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取。 SDS 不是以空字符串来判断是否结束，而是以 len 属性表示的长度来判断字符串是否结束，即二进制安全。

* 兼容C字符串函数，遵从每个字符串都是以空字符串结尾的惯例，这样可以重用 C 语言库`<string.h>` 中的一部分函数。

  

### 2、ZipList（压缩列表）

ziplist是为了提高存储效率而设计的一种特殊编码的双向链表。它可以存储字符串或者整数，存储整数时是采用整数的二进制而不是字符串形式存储。它能在O(1)的时间复杂度下完成list两端的push和pop操作。但是因为每次操作都需要重新分配ziplist的内存，所以实际复杂度和ziplist的内存使用量相关。

优点：省内存。ziplist在设计时就很容易想到要尽量让每个元素按照实际的内容大小存储，同时记录上一个元素的length，以方便定位下一个元素。

缺点：不预留内存空间, 并且在移除结点后, 也是立即缩容, 这代表每次写操作都会进行内存分配操作.



### 3、QuickList（快表）

它是一种以ziplist为结点的双端链表结构. 宏观上, quicklist是一个链表, 微观上, 链表中的每个结点都是一个ziplist。是 **Redis 实现列表类型（List）**的底层数据结构之一。

所以List的查询时间复杂度是O（N)，但是redis中的list不常用查询操作，主要是首尾操作，适合做队列和栈。list的长度获取是O(1)。

为什么使用quickList：

* 单一的大链表会导致节点间指针占用过多内存，所以使用zipList节省内存。
* 单一的压缩列表对大规模数据的操作效率较低，所以分片为多个小的压缩列表。
* QuickList 在列表数据存储上找到了性能和内存使用之间的良好平衡。



### 4、ZSkipList（跳表）

作为有序列表 (Zset) 的使用。跳跃表的性能可以保证在查找，删除，添加等操作的时候在**对数期望时间内完成**，这个性能是可以和平衡树来相比较的，而且在实现方面比平衡树要优雅，这就是跳跃表的长处。

**skiplist与平衡树、哈希表的比较**：

skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。

在做范围查找的时候，平衡树比skiplist操作要复杂。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，**操作简单又快速**。

查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。

跳表的查询操作的时间复杂度虽然为O（log N），但是在redis中**Zset的底层是结合了跳表和哈希表**，从而使得 Redis 的有序集合既能快速进行范围查找，又能高效完成单个元素的更新和删除。

根据分数范围查找O(logn),根据成员值查找分数以及快速判断成员是否存在，时间复杂度O(1).

单个元素的插入删除都要到在跳表和哈希表中同时插入和删除，所以总体时间复杂度还是O(logn).

## 8、Redis对象与底层结构

### 1、集合对象

集合对象的编码可以是 intset 或者 hashtable，底层实现有两种, 分别是intset和dict。显然当使用intset作为底层实现的数据结构时, 集合中存储的只能是数值数据, 且必须是整数; 而当使用dict作为集合对象的底层实现时, 是将数据全部存储于dict的键中, 值字段闲置不用.

`当集合元素为整数且所有元素数量不超过512用intset，其他用hashtable编码。`

### 2、哈希对象

哈希对象的编码可以是 ziplist 或者 hashtable；对应的底层实现有两种, 一种是ziplist, 一种是dict。

压缩列表是Redis为了节省内存而开发的，不能满足这两个条件（`1、列表保存元素个数小于512  2、每个元素长度小于64字节`）的时候使用 hashtable 编码。

### 3、字符串对象

字符串对象的编码可以是int，raw（大于44字节）或者embstr（保存小于44字节）。

embstr的使用只分配一次内存空间（因此redisObject和sds是连续的），而raw需要分配两次内存空间（分别为redisObject和sds分配空间）。

当 int 编码保存的值不再是整数，或大小超过了long的范围时，自动转化为raw。

对于 embstr 编码，由于 Redis 没有对其编写任何的修改程序（embstr 是只读的），在对embstr对象进行修改时，都会先转化为raw再进行修改，因此，只要是修改embstr对象，修改后的对象一定是raw的，无论是否达到了44个字节。

### 4、hyperLogLog

**HyperLogLog** 是一种基于概率的数据结构，用于近似计算集合的基数（即集合中不重复元素的数量）。它通过牺牲一定精确度来显著降低内存消耗，非常适合处理超大规模数据的基数统计。

使用了 **普通的 C 数组** 来存储数据。在 Redis 中，HyperLogLog 的实现非常紧凑，尤其是在稠密模式下，其核心是基于固定大小的数组实现的。 



## 9、Redis性能优化

### lua脚本的缺陷：

Redis事务不支持原子性，持久性也没法保证。可以利用 Lua 脚本来批量执行多条 Redis 命令。 Lua 脚本运行时出错并中途结束，出错之后的命令是不会被执行的。并且，**出错之前执行的命令是无法被撤销的**，无法实现类似关系型数据库执行失败可以回滚的那种原子性效果。因此， 严格来说的话，通过 Lua 脚本来批量执行 Redis 命令实际也是**不完全满足原子性**的。

### 如何处理bigkey:

* 分割bigkey：二次哈希拆分为多个Hash
* 手动清理：使用SCAN命令分批次删除；开启 lazy-free（惰性删除/延迟释放）采用异步方式延迟释放 key 。
* **采用合适的数据结构**：例如，**文件二进制数据不使用 String 保存**（对于特别大的文件，可以将文件切分成多个块，分别存储在 Redis 的 **HASH 或 LIST** 数据结构中。）、使用 HyperLogLog 统计页面 UV、Bitmap 保存状态信息（0/1）如用户是否签到或者缓存是否存在数据库。

### 处理hotkey：

处理 hotkey 会占用大量的 CPU 和带宽，可能会影响 Redis 实例对其他请求的正常处理。

解决办法：

* 读写分离
* Redis Cluster：热点数据分散在多个redis实例中
* 二级缓存/本地缓存

